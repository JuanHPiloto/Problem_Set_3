{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch 12 Networked Programs\n",
    "\n",
    "Chapter 12 of Py4E gets into networked programs, primarily using HyperText Transfer Protocol (http).\n",
    "\n",
    "## Sockets\n",
    "\n",
    "This chapter introduces the concept of a **socket**. This is something that will continue to come up, so is important to understand. \n",
    "\n",
    "In some ways, a socket is like a file handle--it provides access to the information, not the information itself. In other ways a socket is different in that it provides two way communication for sending and recieving information.\n",
    "\n",
    "Here, we'll use sockets to connect to a web server and get the contents of a web page. Different from opening a file on disk, more coordination is needed between your computer and the web server to transmit data, confirm reciept of data, etc. Later, we'll use sockets to connect to databases. And again coordination and established protocols for sending and receiving data come into play.\n",
    "\n",
    "## Protocols\n",
    "\n",
    "As described in the text, in order for two computers to communicate successfully, they need to be following some protocol, or established proceedures for communicating. HTTP is one protocol. We looked briefly at the SFTP (Secure File Transfer Protocol) earlier in the semester for transfering files from our computers to the cluster. Other protocols you are familiar with include Internet Message Access Protocol (IMAP), Post Office Protocol version 3 (POP3) and Simple Mail Transfer Protocol (SMTP) all used for email systems.\n",
    "\n",
    "There are many protocols for different types of communications, the important thing is that you need to establish which protocol is being used and follow the specifications of that protocol.\n",
    "\n",
    "## 12.2 The worldâ€™s simplest web browser (p. 142)\n",
    "\n",
    "Here's the code for socket1.py (remember these are in the code3 directory of the repository)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "HTTP/1.1 200 OK\nDate: Wed, 06 May 2020 13:38:19 GMT\nServer: Apache/2.4.18 (Ubuntu)\nLast-Modified: Sat, 13 May 2017 11:22:22 GMT\nETag: \"a7-54f6609245537\"\nAccept-Ranges: bytes\nContent-Length: 167\nCache-Control: max-age=0, no-cache, no-store, must-revalidate\nPragma: no-cache\nExpires: Wed, 11 Jan 1984 05:00:00 GMT\nConnection: close\nContent-Type: text/plain\n\nBut soft what light through yonder window breaks\nIt is the east and Juliet is the sun\nArise fair sun and kill the envious moon\nWho is already sick and pale with grief\n"
    }
   ],
   "source": [
    "import socket\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512) \n",
    "    if (len(data) < 1):\n",
    "        break\n",
    "    print(data.decode(),end='')\n",
    "\n",
    "mysock.close()\n",
    "\n",
    "# Code: http://www.py4e.com/code3/socket1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the `urljpeg.py` script, which downloads an image, and the information on the script in the text.\n",
    "\n",
    "## 12.4 Retrieving web pages with `urllib`\n",
    "\n",
    "The `urllib` module makes getting stuff from the web a bit easier. The `socket1.py` script above can be simplified to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt') \n",
    "for line in fhand:\n",
    "    print(line.decode().strip())\n",
    "# Code: http://www.py4e.com/code3/urllib1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `urllib` sits between the script and the socket to make an opened socket look just like a file handle and we can treat the web page in much the same way as we treat a local file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.7 Parsing HTML using regular expressions (p. 149)\n",
    "\n",
    "We could write our own scripts to parse HTML looking for information. The example here is using a regular expression to search for a link and make a list of links on a page.\n",
    "\n",
    "Run `urlregex.py` on some site, google.com for example:\n",
    "\n",
    "```bash\n",
    "[magitz@login2 code3]$ python3 urlregex.py\n",
    "Enter - http://google.com\n",
    "http://www.google.com/imghp?hl=en&tab=wi\n",
    "http://maps.google.com/maps?hl=en&tab=wl\n",
    "https://play.google.com/?hl=en&tab=w8\n",
    "http://www.youtube.com/?gl=US&tab=w1\n",
    "http://news.google.com/nwshp?hl=en&tab=wn\n",
    "https://mail.google.com/mail/?tab=wm\n",
    "https://drive.google.com/?tab=wo\n",
    "https://www.google.com/intl/en/options/\n",
    "http://www.google.com/history/optout?hl=en\n",
    "https://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=http://www.google.com/\n",
    "https://plus.google.com/116899029375914044550\n",
    "[magitz@login2 code3]$ \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, not all web pages follow HTML guidelines totally and sometimes pages can be really hard to parse. Tags can be upper and lower case, some closing tags are optional, etc. It can quickly get quite complex.\n",
    "\n",
    "## 12.8 Parsing HTML using BeautifulSoup\n",
    "\n",
    "As I mentioned earlier, whatever you are trying to do, look for a module to make your life easier. If you need to parse HTML, don't start trying to write your own script to do it, look at available modules. One is `BeautifulSoup` available from crummy.com--some people sure have fun naming things!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "https://www.google.com/imghp?hl=en&tab=wi\nhttps://maps.google.com/maps?hl=en&tab=wl\nhttps://play.google.com/?hl=en&tab=w8\nhttps://www.youtube.com/?gl=US&tab=w1\nhttps://news.google.com/nwshp?hl=en&tab=wn\nhttps://mail.google.com/mail/?tab=wm\nhttps://drive.google.com/?tab=wo\nhttps://www.google.com/intl/en/about/products?tab=wh\nhttp://www.google.com/history/optout?hl=en\n/preferences?hl=en\nhttps://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=https://www.google.com/\n/search?ie=UTF-8&q=popular+Google+Doodle+games&oi=ddle&ct=153499290&hl=en&sa=X&ved=0ahUKEwiY6NeisZ_pAhXClXIEHaVpCZMQPQgD\n/advanced_search?hl=en&authuser=0\nhttps://www.google.com/url?q=https://www.youtube.com/stayhome%3Futm_source%3Dgoogle%26utm_medium%3Dhppromo%26utm_campaign%3DHelpathomeYTUS&source=hpp&id=19017550&ct=3&usg=AFQjCNE2FZizHR5ncV3c9xnzo6f1UpGKmQ&sa=X&ved=0ahUKEwiY6NeisZ_pAhXClXIEHaVpCZMQ8IcBCAU\n/intl/en/ads/\n/services/\n/intl/en/about.html\n/intl/en/policies/privacy/\n/intl/en/policies/terms/\n"
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a') \n",
    "for tag in tags:\n",
    "    print(tag.get('href', None))\n",
    "\n",
    "# Code: http://www.py4e.com/code3/urllinks.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}